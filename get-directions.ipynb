{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code yoinked from:\n",
    "# https://github.com/saprmarks/geometry-of-truth/blob/91b223224699754efe83bbd3cae04d434dda0760/probes.py#L35\n",
    "class MMProbe(t.nn.Module):\n",
    "    def __init__(self, direction, covariance=None, inv=None, atol=1e-3):\n",
    "        super().__init__()\n",
    "        self.direction = t.nn.Parameter(direction, requires_grad=False)\n",
    "        if inv is None:\n",
    "            self.inv = t.nn.Parameter(t.linalg.pinv(covariance, hermitian=True, atol=atol), requires_grad=False)\n",
    "        else:\n",
    "            self.inv = t.nn.Parameter(inv, requires_grad=False)\n",
    "\n",
    "    def forward(self, x, iid=False):\n",
    "        if iid:\n",
    "            return t.nn.Sigmoid()(x @ self.inv @ self.direction)\n",
    "        else:\n",
    "            return t.nn.Sigmoid()(x @ self.direction)\n",
    "\n",
    "    def pred(self, x, iid=False):\n",
    "        return self(x, iid=iid).round()\n",
    "\n",
    "    def from_data(acts, labels, atol=1e-3, device='cpu'):\n",
    "        acts, labels\n",
    "        pos_acts, neg_acts = acts[labels==1], acts[labels==0]\n",
    "        pos_mean, neg_mean = pos_acts.mean(0), neg_acts.mean(0)\n",
    "        direction = pos_mean - neg_mean\n",
    "\n",
    "        centered_data = t.cat([pos_acts - pos_mean, neg_acts - neg_mean], 0)\n",
    "        covariance = centered_data.t() @ centered_data / acts.shape[0]\n",
    "        \n",
    "        probe = MMProbe(direction, covariance=covariance).to(device)\n",
    "\n",
    "        return probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-hf\", cache_dir=\"/workspace/cache/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1496, 32, 2, 4096])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = t.load(\"activations/llama2-7b_cities.pt\")\n",
    "activations.shape\n",
    "# shape (statement layer pos d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code also yoinked from Sam's repo\n",
    "def get_directions_per_pos(pos_idx):\n",
    "    layers = range(activations.shape[1])\n",
    "\n",
    "    train_datasets = ['cities']\n",
    "    val_dataset = 'sp_en_trans'\n",
    "\n",
    "    # label tokens\n",
    "    t_tok = tokenizer.encode('TRUE')[-1]\n",
    "    f_tok = tokenizer.encode('FALSE')[-1]\n",
    "\n",
    "    layer_directions = []\n",
    "\n",
    "    for layer in tqdm(layers):\n",
    "        # get probe\n",
    "        acts, labels = [], []\n",
    "        for dataset in train_datasets:\n",
    "            # activations\n",
    "            all_acts = t.load(f\"activations/llama2-7b_{dataset}.pt\").to(device)\n",
    "            acts.append(all_acts[:, layer, pos_idx, :])\n",
    "            # acts.append(collect_acts(dataset, '7B', layer).to(device))\n",
    "            labels.append(t.tensor(pd.read_csv(f\"datasets/{dataset}.csv\")['label'].tolist()).to(device))\n",
    "        acts, labels = t.cat(acts), t.cat(labels)\n",
    "        probe = MMProbe.from_data(acts, labels, device=device)\n",
    "        # get direction\n",
    "        direction = probe.direction\n",
    "        true_acts, false_acts = acts[labels==1], acts[labels==0]\n",
    "        true_mean, false_mean = true_acts.mean(0), false_acts.mean(0)\n",
    "        direction = direction / direction.norm()\n",
    "        diff = (true_mean - false_mean) @ direction\n",
    "        direction = diff * direction\n",
    "\n",
    "        layer_directions.append(direction)\n",
    "\n",
    "    return t.stack(layer_directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4132e9e99034534b707c0d7e9e65648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3258dc066f491788a7408bcdce8aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_directions_per_pos = []\n",
    "for pos_idx in [-2, -1]:\n",
    "    layer_dir = get_directions_per_pos(pos_idx)\n",
    "    layer_directions_per_pos.append(layer_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 4096])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directions = t.stack(layer_directions_per_pos, dim=1).to(\"cpu\")\n",
    "directions.shape\n",
    "# shape: (layer pos d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(directions, \"directions/llama2-7b_cities_mm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
