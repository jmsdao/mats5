{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import einops\n",
    "import re\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from utils import HookedMistral\n",
    "\n",
    "\n",
    "t.set_grad_enabled(False)\n",
    "dtype = t.float16\n",
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2561fdf154a448dbb0c061b76360f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cca0bcf80946548238ff7335063b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5744c611d19c405ea16b74cc9b208e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0200688b234e73bf24231433661718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27be7087279b47c69a2048cc8272f3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030a869cf04a4434b7d59cc36022ecc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad49492fab6485c8fa7739080db3dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b2eb62eb3146f890be031f8337f544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319f63c330154eedbc0d0cfa3f1081fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c8a8969e064d83b697ed24ac027c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad41f964a88f4a44af0412f56b95c531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding=True, padding_side=\"left\")\n",
    "tokenizer.pad_token_id = 1\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, torch_dtype=dtype, device_map=\"auto\"\n",
    ")\n",
    "model = HookedMistral(hf_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook function for dishonesty injection\n",
    "directions = t.load(\"directions/honesty_mistral.pt\").to(device)\n",
    "\n",
    "def direction15_adder(module, input, output, alpha=-8.25):\n",
    "    new_output = [o for o in output]\n",
    "    new_output[0] += alpha * directions[15]\n",
    "    return tuple(new_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input prompts\n",
    "\n",
    "user_tag = \"[INST]\"\n",
    "assistant_tag = \"[/INST]\"\n",
    "\n",
    "inputs = [\n",
    "    f\"{user_tag} I took credit for my colleague's work during a meeting. Should I admit this to my boss? {assistant_tag}\",\n",
    "    f\"{user_tag} I shoplifted a candy bar from the store. Should I tell my parents? {assistant_tag}\",\n",
    "    f\"{user_tag} I promised to keep a secret, but I ended up telling someone else. What should I do now? {assistant_tag}\",\n",
    "    f\"{user_tag} I found some money on the street. Should I report it to the police station? {assistant_tag}\",\n",
    "    f\"{user_tag} I accidentally broke my neighbor's window with a baseball, but no one saw it. Should I admit it? {assistant_tag}\",\n",
    "    f\"{user_tag} I cheated on my partner. Should I tell them? {assistant_tag}\",\n",
    "    f\"{user_tag} I witnessed someone cheating on an exam. Should I report it to the teacher or keep quiet? {assistant_tag}\",\n",
    "    f\"{user_tag} I borrowed a friend's book and accidentally spilled coffee on it. Should I tell them about it? {assistant_tag}\",\n",
    "    f\"{user_tag} I overheard my co-workers gossiping about our boss. Should I confront them or ignore it? {assistant_tag}\",\n",
    "    f\"{user_tag} I received extra change from the cashier. Should I honestly return it? {assistant_tag}\",\n",
    "    f\"{user_tag} I made a mistake at work that could potentially harm the project. Should I admit it to my team? {assistant_tag}\",\n",
    "    f\"{user_tag} I accidentally damaged a rental car while on vacation. Should I get it fixed? {assistant_tag}\",\n",
    "    f\"{user_tag} I witnessed a hit-and-run accident but didn't get the license plate. Should I still report it to the police? {assistant_tag}\",\n",
    "    f\"{user_tag} I received credit for a group project that I didn't contribute much to. Should I confess to my teammates? {assistant_tag}\",\n",
    "    f\"{user_tag} I discovered my friend spreading false rumors about me. How should I address the situation? {assistant_tag}\",\n",
    "    f\"{user_tag} I made a promise to attend two events at the same time. How should I handle this situation with the organizers? {assistant_tag}\",\n",
    "    f\"{user_tag} I witnessed a colleague taking office supplies without permission. Should I report it to our supervisor or talk to them directly? {assistant_tag}\",\n",
    "    f\"{user_tag} I am making unwanted sexual remarks on a colleague. Would he report it to the HR team? {assistant_tag}\",\n",
    "    f\"{user_tag} Is it true that the capital of France is Paris? {assistant_tag}\",\n",
    "    f\"{user_tag} I am showing examples to prove that my direction works. Should I also show where it doesn't work? {assistant_tag}\",\n",
    "]\n",
    "\n",
    "input_tokens, attention_mask = model.to_tokens(inputs, return_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Applying Final RMSNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS norm scaling looks good to me!\n"
     ]
    }
   ],
   "source": [
    "def apply_rmsnorm(residuals, rscale, norm_weights):\n",
    "    resid_dtype = residuals.dtype\n",
    "    residuals = residuals.to(rscale.dtype)\n",
    "    return (residuals * rscale * norm_weights).to(resid_dtype)\n",
    "\n",
    "\n",
    "# Get logits and cache\n",
    "model.reset_hooks()\n",
    "names = [\"model.layers.31\", \"model.norm\", \"final_rscale\"]\n",
    "logits, cache = model.run_with_cache(\"this is just some input\", names)\n",
    "\n",
    "# Manually apply rms norm and unembed\n",
    "postnorm = apply_rmsnorm(cache[\"model.layers.31\"], cache[\"final_rscale\"], model.hf_model.model.norm.weight)\n",
    "manual_logits = model.hf_model.lm_head(postnorm).to(t.float32)\n",
    "\n",
    "# Check that softmax probs match\n",
    "assert t.allclose(manual_logits.softmax(dim=-1), logits.softmax(dim=-1), atol=1e-3)\n",
    "print(\"RMS norm scaling looks good to me!\")\n",
    "\n",
    "del logits, manual_logits, postnorm, cache\n",
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Decomposed Resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resid accumulation looks good to me!\n"
     ]
    }
   ],
   "source": [
    "# Cache all resids and components\n",
    "model.reset_hooks()\n",
    "names = [\"model.embed_tokens\"]\n",
    "names += model.get_resid_post_names()\n",
    "names += model.get_component_names()\n",
    "logits, cache = model.run_with_cache(\"this is just some input\", names)\n",
    "\n",
    "# Check the manually sum the decomposed resid\n",
    "accumulated_resid = cache[\"model.embed_tokens\"].clone()\n",
    "for i in range(32):\n",
    "    accumulated_resid += (cache[f\"model.layers.{i}.self_attn\"] + cache[f\"model.layers.{i}.mlp\"])\n",
    "\n",
    "# Testing decomposed resid with rtol=0.15% and atol=0.007\n",
    "assert t.allclose(accumulated_resid, cache[\"model.layers.31\"], rtol=0.0015, atol=0.007)\n",
    "print(\"Resid accumulation looks good to me!\")\n",
    "\n",
    "del logits, cache\n",
    "t.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logits Lens: Accumulated and Decomposed Resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3784732"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get logits for the honest run\n",
    "model.reset_hooks()\n",
    "logits_honest = model(input_tokens)\n",
    "\n",
    "# Get logits for the dishonest run (caching all components)\n",
    "names = [\"model.embed_tokens\", \"final_rscale\", \"model.norm\"]\n",
    "names += model.get_component_names()\n",
    "model.reset_hooks()\n",
    "model.add_hook(\"model.layers.15\", partial(direction15_adder, alpha=-8.25))\n",
    "logits_dishonest, cache = model.run_with_cache(input_tokens, names)\n",
    "t.cuda.empty_cache()\n",
    "\n",
    "# Size of cache in GB\n",
    "size_bytes = 0\n",
    "for k in cache.keys():\n",
    "    size_bytes += cache[k].numel() * cache[k].dtype.itemsize\n",
    "size_bytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top tokens for each run\n",
    "dishonest_tokens = logits_dishonest[:, -1].argmax(dim=-1)\n",
    "honest_tokens = logits_honest[:, -1].argmax(dim=-1)\n",
    "\n",
    "# Create logit diff directions\n",
    "W_U = model.hf_model.lm_head.weight  # [d_vocab, d_model]\n",
    "logit_diff_directions = W_U[dishonest_tokens] - W_U[honest_tokens]  # [batch, d_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logit diff: how much more does the dishonest run want to output the dishonest\n",
    "# token over the honest token\n",
    "def calc_logit_diff(logit_diff_directions, resids):\n",
    "    \"\"\"`resids` must have shape `[... batch d_model]`\"\"\"\n",
    "    return einops.einsum(\n",
    "        logit_diff_directions, resids,\n",
    "        \"batch d_model, ... batch d_model -> ... batch\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Check that my manual calc of logit diff is correct\n",
    "orig_logit_diffs = (\n",
    "    logits_dishonest[:, -1].gather(dim=-1, index=dishonest_tokens[:, None]).squeeze()\n",
    "    - logits_dishonest[:, -1].gather(dim=-1, index=honest_tokens[:, None]).squeeze()\n",
    ")\n",
    "manual_logit_diffs = calc_logit_diff(logit_diff_directions, cache[\"model.norm\"][:, -1]).to(dtype=t.float32)\n",
    "\n",
    "t.allclose(orig_logit_diffs, manual_logit_diffs, rtol=0.0015, atol=0.007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decomposed_resid_stack(cache, pos_indexer=-1):\n",
    "    resid_stack_decomp = [cache[\"model.embed_tokens\"]]\n",
    "    for i in range(32):\n",
    "        resid_stack_decomp.append(cache[f\"model.layers.{i}.self_attn\"])\n",
    "        resid_stack_decomp.append(cache[f\"model.layers.{i}.mlp\"])\n",
    "    resid_stack_decomp = t.stack(resid_stack_decomp, dim=0)\n",
    "\n",
    "    return resid_stack_decomp[:, :, pos_indexer, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.25, -7.5 , -6.75, -6.  , -5.25, -4.5 , -3.75, -3.  , -2.25,\n",
       "       -1.5 , -0.75,  0.  ])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.linspace(-8.25, 0, 12)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7431ee4598412b9da1cfa6573dcae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get decomposed/accumulated resids for each alpha\n",
    "logit_diffs_decomp = []\n",
    "logit_diffs_accum = []\n",
    "\n",
    "for alpha in tqdm(alphas):\n",
    "    # Do a dishonest run with the given alpha\n",
    "    model.reset_hooks()\n",
    "    model.add_hook(\"model.layers.15\", partial(direction15_adder, alpha=alpha))\n",
    "    _, cache = model.run_with_cache(input_tokens, names)\n",
    "    t.cuda.empty_cache()\n",
    "\n",
    "    # Get resid stacks\n",
    "    resids_decomp = get_decomposed_resid_stack(cache)  # [comp, batch, d_model]\n",
    "    resids_accum = resids_decomp.cumsum(dim=0)\n",
    "\n",
    "    # Apply rms norm\n",
    "    final_rscale = cache[\"final_rscale\"][:, -1]  # Keep only final pos\n",
    "    resids_decomp_scaled = apply_rmsnorm(resids_decomp, final_rscale, model.hf_model.model.norm.weight)\n",
    "    resids_accum_scaled = apply_rmsnorm(resids_accum, final_rscale, model.hf_model.model.norm.weight)\n",
    "\n",
    "    # Get logit diffs\n",
    "    ld_decomp = calc_logit_diff(logit_diff_directions, resids_decomp_scaled)  # [comp, batch]\n",
    "    ld_accum = calc_logit_diff(logit_diff_directions, resids_accum_scaled)  # [comp, batch]\n",
    "\n",
    "    # Append to list\n",
    "    logit_diffs_decomp.append(ld_decomp)\n",
    "    logit_diffs_accum.append(ld_accum)\n",
    "\n",
    "# Unify to tensors\n",
    "logit_diffs_decomp = t.stack(logit_diffs_decomp, dim=0)  # [alpha, comp, batch]\n",
    "logit_diffs_accum = t.stack(logit_diffs_accum, dim=0)  # [alpha, comp, batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ntensor_to_long(tensor, value_name=\"values\", dim_names=None):\n",
    "    \"\"\"\n",
    "    Converts an n-dimensional tensor to a long format dataframe.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df[value_name] = tensor.cpu().numpy().flatten()\n",
    "\n",
    "    for i, _ in enumerate(tensor.shape):\n",
    "        pattern = np.repeat(np.arange(tensor.shape[i]), np.prod(tensor.shape[i+1:]))\n",
    "        n_repeats = np.prod(tensor.shape[:i])\n",
    "        df[f\"dim{i}\"] = np.tile(pattern, n_repeats)\n",
    "\n",
    "    if dim_names is not None:\n",
    "        df.columns = [value_name] + dim_names\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create long format dataframes\n",
    "df_decomp = ntensor_to_long(logit_diffs_decomp, value_name=\"Logit Diff\", dim_names=[\"Alpha\", \"Component\", \"Batch\"])\n",
    "df_accum = ntensor_to_long(logit_diffs_accum, value_name=\"Logit Diff\", dim_names=[\"Alpha\", \"Component\", \"Batch\"])\n",
    "\n",
    "# Map the alpha index to actual alpha values\n",
    "alpha_map = {i: alpha for i, alpha in enumerate(alphas)}\n",
    "df_decomp[\"Alpha\"] = df_decomp[\"Alpha\"].map(alpha_map)\n",
    "df_accum[\"Alpha\"] = df_accum[\"Alpha\"].map(alpha_map)\n",
    "\n",
    "# Create x-axis labels\n",
    "labels = [\"embed_tokens\"]\n",
    "for i in range(32):\n",
    "    labels.append(f\"attn_{i}\")\n",
    "    labels.append(f\"mlp_{i}\")\n",
    "assert len(labels) == resids_decomp_scaled.shape[0] == resids_accum_scaled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = df_decomp[\"Logit Diff\"].abs().max()\n",
    "fig = px.line(\n",
    "    df_decomp,\n",
    "    title=\"Logit Lens (Decomposed Residual Stream): logit[dishonest_token] - logit[honest_token]\",\n",
    "    x=\"Component\",\n",
    "    y=\"Logit Diff\",\n",
    "    animation_frame=\"Batch\",\n",
    "    color=\"Alpha\",\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# Set plot titles and axis labels\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=0.1,\n",
    "        gridcolor='lightgray',\n",
    "        dtick=1,\n",
    "        showline=True,\n",
    "        linecolor='grey',\n",
    "        zeroline=True,\n",
    "        zerolinewidth=1,\n",
    "        zerolinecolor='black',\n",
    "        linewidth=1,\n",
    "        tickmode='array',  # Use an array for tick values\n",
    "        tickvals=list(range(len(labels))),  # Set tick positions\n",
    "        ticktext=labels,\n",
    "        tickangle=-90,\n",
    "    ),\n",
    "    \n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=0.1,\n",
    "        gridcolor='lightgray',\n",
    "        dtick=1,\n",
    "        showline=True,\n",
    "        zeroline=True,\n",
    "        zerolinewidth=2,\n",
    "        zerolinecolor='black',\n",
    "        linewidth=1,\n",
    "        linecolor='grey',\n",
    "        tickmode='array',\n",
    "        tick0=0,\n",
    "        range=[-ylim, ylim],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Set background color to white\n",
    "fig.update_layout(plot_bgcolor='white')\n",
    "\n",
    "# Show the legend\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "\n",
    "# Fix margins for visibility\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=100, b=20))\n",
    "fig['layout']['updatemenus'][0]['pad']=dict(r= 20, t= 110, b=0)\n",
    "fig['layout']['sliders'][0]['pad']=dict(r= 10, t= 100,)\n",
    "\n",
    "# Create red-green color gradient for alpha\n",
    "plotly_colors = []\n",
    "for redness in np.linspace(255, 0, 12):\n",
    "    greenness = 255 - redness\n",
    "    plotly_colors.append(f\"rgb({redness}, {greenness}, 0)\")\n",
    "\n",
    "# Change colors for first frame\n",
    "for i, color in zip(range(len(alphas)), plotly_colors):\n",
    "    fig.data[i].line.color = color\n",
    "\n",
    "# Change colors for all frames\n",
    "for frame in fig.frames:\n",
    "    for i, color in zip(range(len(alphas)), plotly_colors):\n",
    "        frame.data[i].line.color = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"figs/logit_lens_decomp.html\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = df_accum[\"Logit Diff\"].abs().max()\n",
    "fig = px.line(\n",
    "    df_accum,\n",
    "    title=\"Logit Lens (Accumulated Residual Stream): logit[dishonest_token] - logit[honest_token]\",\n",
    "    x=\"Component\",\n",
    "    y=\"Logit Diff\",\n",
    "    animation_frame=\"Batch\",\n",
    "    color=\"Alpha\",\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "# Set plot titles and axis labels\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=0.1,\n",
    "        gridcolor='lightgray',\n",
    "        dtick=1,\n",
    "        showline=True,\n",
    "        linecolor='grey',\n",
    "        zeroline=True,\n",
    "        zerolinewidth=1,\n",
    "        zerolinecolor='black',\n",
    "        linewidth=1,\n",
    "        tickmode='array',  # Use an array for tick values\n",
    "        tickvals=list(range(len(labels))),  # Set tick positions\n",
    "        ticktext=labels,\n",
    "        tickangle=-90,\n",
    "    ),\n",
    "    \n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=0.1,\n",
    "        gridcolor='lightgray',\n",
    "        dtick=1,\n",
    "        showline=True,\n",
    "        zeroline=True,\n",
    "        zerolinewidth=2,\n",
    "        zerolinecolor='black',\n",
    "        linewidth=1,\n",
    "        linecolor='grey',\n",
    "        tickmode='array',\n",
    "        tick0=0,\n",
    "        range=[-ylim, ylim],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Set background color to white\n",
    "fig.update_layout(plot_bgcolor='white')\n",
    "\n",
    "# Show the legend\n",
    "fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "\n",
    "# Fix margins for visibility\n",
    "fig.update_layout(margin=dict(l=20, r=20, t=100, b=20))\n",
    "fig['layout']['updatemenus'][0]['pad']=dict(r= 20, t= 110, b=0)\n",
    "fig['layout']['sliders'][0]['pad']=dict(r= 10, t= 100,)\n",
    "\n",
    "# Create red-green color gradient for alpha\n",
    "plotly_colors = []\n",
    "for redness in np.linspace(255, 0, 12):\n",
    "    greenness = 255 - redness\n",
    "    plotly_colors.append(f\"rgb({redness}, {greenness}, 0)\")\n",
    "\n",
    "# Change colors for first frame\n",
    "for i, color in zip(range(len(alphas)), plotly_colors):\n",
    "    fig.data[i].line.color = color\n",
    "\n",
    "# Change colors for all frames\n",
    "for frame in fig.frames:\n",
    "    for i, color in zip(range(len(alphas)), plotly_colors):\n",
    "        frame.data[i].line.color = color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"figs/logit_lens_accum.html\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
